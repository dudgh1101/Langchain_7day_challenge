import json
import os
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema.runnable import RunnablePassthrough
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# LLM ì„¸íŒ…
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.1
)

# JSON ì €ì¥ì†Œ íŒŒì¼
HISTORY_FILE = "chat_history.json"

# JSON íŒŒì¼ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ìƒì„±)
if not os.path.exists(HISTORY_FILE):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump([], f, ensure_ascii=False, indent=2)


def load_history():
    """json íŒŒì¼ì—ì„œ ëŒ€í™” ì´ë ¥ ë¶ˆëŸ¬ì˜¤ê¸°"""
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def save_history(history):
    """ëŒ€í™” ì´ë ¥ì„ json íŒŒì¼ì— ì €ì¥"""
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


# Prompt í…œí”Œë¦¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI talking to a human"),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{question}")
])

def load_memory(_):
    history = load_history()
    # langchain MessagesPlaceholderì— ë§ê²Œ ë³€í™˜
    return [{"role": h["role"], "content": h["content"]} for h in history]


chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm


def invoke_chain(question):
    history = load_history()

    result = chain.invoke({"question": question})
    ai_response = result.content

    # JSONì— ì‚¬ìš©ì ì…ë ¥/AI ì‘ë‹µ ì¶”ê°€
    history.append({"role": "human", "content": question})
    history.append({"role": "ai", "content": ai_response})
    save_history(history)
    return ai_response


def print_history():
    history = load_history()

    print("\nğŸ“œ í˜„ì¬ JSON ëŒ€í™” ë‚´ì—­:")
    print(json.dumps(history, ensure_ascii=False, indent=2))

def run_cli_chatbot():
    print("(ì¢…ë£Œí•˜ë ¤ë©´ exit ì…ë ¥)")
    while True:
        user_input = input("You: ").strip()

        if user_input.lower() in ["exit", "quit"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if user_input.lower() in ["chat_history"]:
            print_history()
            continue

        response = invoke_chain(user_input)
        print(f"\nAI: {response}\n")


if __name__ == "__main__":
    run_cli_chatbot()
